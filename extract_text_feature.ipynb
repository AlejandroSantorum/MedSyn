{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f4c2641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from modeling_cxrbert import CXRBertModel\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f77edc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_name = 'microsoft/BiomedVLP-CXR-BERT-specialized'\n",
    "resume_model = './results/test_run2'\n",
    "\n",
    "max_seq_length = 2048\n",
    "hidden_size = 768\n",
    "save_seq_len = 192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "130ec5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CXRBertModel were not initialized from the model checkpoint at microsoft/BiomedVLP-CXR-BERT-specialized and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = CXRBertModel.from_pretrained(base_model_name)\n",
    "\n",
    "# extend embeddings\n",
    "old_embed = model.bert.embeddings.position_embeddings.weight.data\n",
    "tmp_dim = old_embed.shape[0]\n",
    "#print(\"tmp_dim:\", tmp_dim)\n",
    "model.bert.embeddings.position_embeddings = nn.Embedding(max_seq_length, hidden_size)\n",
    "model.bert.embeddings.position_embeddings.weight.data[:tmp_dim, :] = old_embed\n",
    "model.bert.embeddings.register_buffer(\"position_ids\", torch.arange(max_seq_length).expand((1, -1)))\n",
    "model.config.max_position_embeddings = max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e76102e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "ckpt = torch.load(resume_model+\"/pytorch_model.bin\")\n",
    "\n",
    "msg = model.load_state_dict(ckpt, strict=False)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "545b3746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CXRBertModel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(2048, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (cls_projection_head): BertProjectionHead(\n",
       "    (dense_to_hidden): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "    (dense_to_output): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       "  (classifier): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (loss_fct): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a8fcec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5d82b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example_text):\n",
    "    # Remove empty lines\n",
    "\n",
    "    return tokenizer(\n",
    "        example_text,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_seq_length,\n",
    "        # We use this option because DataCollatorForLanguageModeling (see below) is more efficient when it\n",
    "        # receives the `special_tokens_mask`.\n",
    "        return_special_tokens_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baaf433",
   "metadata": {},
   "source": [
    "### Consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a268a081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'special_tokens_mask', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "# 578558513: 40336413\n",
    "example_text_0='No consolidation is identified. No pulmonary nodules are noted. Bone windowed images demonstrate no lytic or blastic lesions.,No evidence of pulmonary embolus.'\n",
    "\n",
    "example_0=tokenize_function(example_text_0)\n",
    "for item in example_0.keys():\n",
    "    example_0[item] = example_0[item].cuda()\n",
    "    \n",
    "print(example_0.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7b32f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    feature_0 = model(**example_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "076c37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_0_np = feature_0.hidden_states[-1][:, :save_seq_len, :].detach().cpu().numpy()\n",
    "feature_0_np.shape\n",
    "\n",
    "np.save(\"./results/text_embed_example/no_consolidation.npy\", feature_0_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ebadac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 768)\n"
     ]
    }
   ],
   "source": [
    "example_text_1='There is extensive consolidation seen. No pulmonary nodules are noted. Bone windowed images demonstrate no lytic or blastic lesions.,No evidence of pulmonary embolus.'\n",
    "\n",
    "example_1=tokenize_function(example_text_1)\n",
    "for item in example_1.keys():\n",
    "    example_1[item] = example_1[item].cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    feature_1 = model(**example_1)\n",
    "    \n",
    "feature_1_np = feature_1.hidden_states[-1][:, :save_seq_len, :].detach().cpu().numpy()\n",
    "print(feature_1_np.shape)\n",
    "\n",
    "np.save(\"./results/text_embed_example/extensive_consolidation.npy\", feature_1_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93efd3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 768)\n"
     ]
    }
   ],
   "source": [
    "example_text_1='There is extensive consolidation seen. No evidence of cardiomegaly. No evidence of pleural effusion.'\n",
    "\n",
    "example_1=tokenize_function(example_text_1)\n",
    "for item in example_1.keys():\n",
    "    example_1[item] = example_1[item].cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    feature_1 = model(**example_1)\n",
    "    \n",
    "feature_1_np = feature_1.hidden_states[-1][:, :save_seq_len, :].detach().cpu().numpy()\n",
    "print(feature_1_np.shape)\n",
    "\n",
    "np.save(\"./results/text_embed_example/extensive_consolidation_v2.npy\", feature_1_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4df04c3",
   "metadata": {},
   "source": [
    "### Effusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f1f803f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 768)\n"
     ]
    }
   ],
   "source": [
    "# 512492223: 42507796\n",
    "example_text='There is no airspace opacity, effusion or pneumothorax. There is no evidence of suspicious pulmonary nodule or mass.'\n",
    "\n",
    "example=tokenize_function(example_text)\n",
    "for item in example.keys():\n",
    "    example[item] = example[item].cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    feature = model(**example)\n",
    "    \n",
    "feature_np = feature.hidden_states[-1][:, :save_seq_len, :].detach().cpu().numpy()\n",
    "print(feature_np.shape)\n",
    "\n",
    "np.save(\"./results/text_embed_example/no_effusion.npy\", feature_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4c5f767f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 768)\n"
     ]
    }
   ],
   "source": [
    "example_text='There are large pleural effusions seen. There is no airspace opacity or pneumothorax. There is no evidence of suspicious pulmonary nodule or mass.'\n",
    "\n",
    "example=tokenize_function(example_text)\n",
    "for item in example.keys():\n",
    "    example[item] = example[item].cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    feature = model(**example)\n",
    "    \n",
    "feature_np = feature.hidden_states[-1][:, :save_seq_len, :].detach().cpu().numpy()\n",
    "print(feature_np.shape)\n",
    "\n",
    "np.save(\"./results/text_embed_example/large_effusion.npy\", feature_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af87f71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 768)\n"
     ]
    }
   ],
   "source": [
    "example_text='There are large pleural effusions seen. No evidence of cardiomegaly. No evidence of consolidation.'\n",
    "\n",
    "example=tokenize_function(example_text)\n",
    "for item in example.keys():\n",
    "    example[item] = example[item].cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    feature = model(**example)\n",
    "    \n",
    "feature_np = feature.hidden_states[-1][:, :save_seq_len, :].detach().cpu().numpy()\n",
    "print(feature_np.shape)\n",
    "\n",
    "np.save(\"./results/text_embed_example/large_effusion_v2.npy\", feature_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7d60d0",
   "metadata": {},
   "source": [
    "### bullae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4b6350b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 768)\n"
     ]
    }
   ],
   "source": [
    "# 511638018: 42258969\n",
    "example_text='No bullae, cystic lung disease, or CT findings of small airways disease.'\n",
    "\n",
    "example=tokenize_function(example_text)\n",
    "for item in example.keys():\n",
    "    example[item] = example[item].cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    feature = model(**example)\n",
    "    \n",
    "feature_np = feature.hidden_states[-1][:, :save_seq_len, :].detach().cpu().numpy()\n",
    "print(feature_np.shape)\n",
    "\n",
    "np.save(\"./results/text_embed_example/no_bullae.npy\", feature_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "153fea16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 768)\n"
     ]
    }
   ],
   "source": [
    "# 456867906: 49263717\n",
    "example_text='Emphysema is present with bullae. No cystic lung disease, or CT findings of small airways disease.'\n",
    "\n",
    "example=tokenize_function(example_text)\n",
    "for item in example.keys():\n",
    "    example[item] = example[item].cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    feature = model(**example)\n",
    "    \n",
    "feature_np = feature.hidden_states[-1][:, :save_seq_len, :].detach().cpu().numpy()\n",
    "print(feature_np.shape)\n",
    "\n",
    "np.save(\"./results/text_embed_example/with_bullae.npy\", feature_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff2e1b7",
   "metadata": {},
   "source": [
    "### cardiomegaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cad6f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 768)\n"
     ]
    }
   ],
   "source": [
    "# 573143138: 40519238\n",
    "example_text='No cardiomegaly demonstrated.'\n",
    "\n",
    "example=tokenize_function(example_text)\n",
    "for item in example.keys():\n",
    "    example[item] = example[item].cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    feature = model(**example)\n",
    "    \n",
    "feature_np = feature.hidden_states[-1][:, :save_seq_len, :].detach().cpu().numpy()\n",
    "print(feature_np.shape)\n",
    "\n",
    "np.save(\"./results/text_embed_example/no_cardiomegaly.npy\", feature_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d5f7257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 768)\n"
     ]
    }
   ],
   "source": [
    "# 502156754: 42759222\n",
    "example_text='There is cardiomegaly.'\n",
    "\n",
    "example=tokenize_function(example_text)\n",
    "for item in example.keys():\n",
    "    example[item] = example[item].cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    feature = model(**example)\n",
    "    \n",
    "feature_np = feature.hidden_states[-1][:, :save_seq_len, :].detach().cpu().numpy()\n",
    "print(feature_np.shape)\n",
    "\n",
    "np.save(\"./results/text_embed_example/with_cardiomegaly.npy\", feature_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12e3a03b-cd64-49e6-8de5-7700df3c9517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 768)\n"
     ]
    }
   ],
   "source": [
    "example_text='There is no significant mediastinal lymphadenopathy. There is no cardiomegaly demonstrated. The visualized upper abdominal organs are unremarkable. There is minimal perihepatic free fluid.'\n",
    "\n",
    "example=tokenize_function(example_text)\n",
    "for item in example.keys():\n",
    "    example[item] = example[item].cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    feature = model(**example)\n",
    "    \n",
    "feature_np = feature.hidden_states[-1][:, :save_seq_len, :].detach().cpu().numpy()\n",
    "print(feature_np.shape)\n",
    "\n",
    "np.save(\"./results/text_embed_example/no_cardiomegaly_v2.npy\", feature_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d53958f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 768)\n"
     ]
    }
   ],
   "source": [
    "# 506275596\n",
    "example_text='There is no significant mediastinal lymphadenopathy. There is moderate cardiomegaly. The visualized upper abdominal organs are unremarkable. There is minimal perihepatic free fluid.'\n",
    "\n",
    "example=tokenize_function(example_text)\n",
    "for item in example.keys():\n",
    "    example[item] = example[item].cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    feature = model(**example)\n",
    "    \n",
    "feature_np = feature.hidden_states[-1][:, :save_seq_len, :].detach().cpu().numpy()\n",
    "print(feature_np.shape)\n",
    "\n",
    "np.save(\"./results/text_embed_example/with_cardiomegaly_v2.npy\", feature_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f05175c9-a7b1-45ed-8241-8b5388ae22ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 768)\n"
     ]
    }
   ],
   "source": [
    "# 502156754\n",
    "example_text='Lungs: There is pulmonary fibrosis present with honeycombing demonstrated involving a significant portion of the bilateral lower lung zones. There are small areas of honeycombing in the anterior lateral right lung apex. There is no focal consolidation or pulmonary mass lesion demonstrated. There are a few areas of groundglass opacity in the right lung present, but the major finding is the pulmonary fibrosis that is most significant in the basilar regions. Pleural spaces:  There are small bilateral pleural effusions. There are no areas of significant pleural thickening demonstrated. Mediastinum and Lymph Nodes:  There is no pathologic adenopathy demonstrated in the axilla, mediastinum, or hilar regions. Heart and vascular structures: There is cardiomegaly. There is a cardiac pacemaker in place. There are small areas of atherosclerotic disease present, likely to include in the coronary arteries. There is no aneurysmal dilatation of the thoracic aorta. There is no significant pericardial effusion. Esophagus and visualized portion of the gastrointestinal tract: There is a mildly dilated partially fluid-filled distal esophagus. This could represent a hiatal hernia. Osseous structures and chest wall:  Unremarkable without acute or significant non-degenerative abnormalities. Visualized portion of the lower neck:  No major abnormalities are demonstrated in the portion of the neck included on this chest CT scan. Visualized portion of the upper abdomen:  There is ascites present with a small amount of fluid surrounding the liver and spleen. There is significant pulmonary fibrosis present, with large areas of honeycombing present involving both lower lung zones. There are milder areas of abnormality in the subpleural right greater than left upper lung zones. There are mild areas of groundglass opacity in the right upper lung zone, but there is no consolidation in the lungs. There are no suspicious pulmonary mass lesions. There are very small bilateral pleural effusions. There is at least mild ascites seen in the portion of the upper abdomen included on this exam.'\n",
    "\n",
    "example=tokenize_function(example_text)\n",
    "for item in example.keys():\n",
    "    example[item] = example[item].cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    feature = model(**example)\n",
    "    \n",
    "feature_np = feature.hidden_states[-1][:, :save_seq_len, :].detach().cpu().numpy()\n",
    "print(feature_np.shape)\n",
    "\n",
    "np.save(\"./results/text_embed_example/with_cardiomegaly_v3.npy\", feature_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "794284b3-b11e-4fc2-a848-37f55ecaa93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 768)\n"
     ]
    }
   ],
   "source": [
    "example_text='Lungs: There is pulmonary fibrosis present with honeycombing demonstrated involving a significant portion of the bilateral lower lung zones. There are small areas of honeycombing in the anterior lateral right lung apex. There is no focal consolidation or pulmonary mass lesion demonstrated. There are a few areas of groundglass opacity in the right lung present, but the major finding is the pulmonary fibrosis that is most significant in the basilar regions. Pleural spaces:  There are small bilateral pleural effusions. There are no areas of significant pleural thickening demonstrated. Mediastinum and Lymph Nodes:  There is no pathologic adenopathy demonstrated in the axilla, mediastinum, or hilar regions. Heart and vascular structures: There is no cardiomegaly. There is a cardiac pacemaker in place. There are small areas of atherosclerotic disease present, likely to include in the coronary arteries. There is no aneurysmal dilatation of the thoracic aorta. There is no significant pericardial effusion. Esophagus and visualized portion of the gastrointestinal tract: There is a mildly dilated partially fluid-filled distal esophagus. This could represent a hiatal hernia. Osseous structures and chest wall:  Unremarkable without acute or significant non-degenerative abnormalities. Visualized portion of the lower neck:  No major abnormalities are demonstrated in the portion of the neck included on this chest CT scan. Visualized portion of the upper abdomen:  There is ascites present with a small amount of fluid surrounding the liver and spleen. There is significant pulmonary fibrosis present, with large areas of honeycombing present involving both lower lung zones. There are milder areas of abnormality in the subpleural right greater than left upper lung zones. There are mild areas of groundglass opacity in the right upper lung zone, but there is no consolidation in the lungs. There are no suspicious pulmonary mass lesions. There are very small bilateral pleural effusions. There is at least mild ascites seen in the portion of the upper abdomen included on this exam.'\n",
    "\n",
    "example=tokenize_function(example_text)\n",
    "for item in example.keys():\n",
    "    example[item] = example[item].cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    feature = model(**example)\n",
    "    \n",
    "feature_np = feature.hidden_states[-1][:, :save_seq_len, :].detach().cpu().numpy()\n",
    "print(feature_np.shape)\n",
    "\n",
    "np.save(\"./results/text_embed_example/no_cardiomegaly_v3.npy\", feature_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5876e567-b7aa-4cb4-9c64-6b82be6f30c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 768)\n"
     ]
    }
   ],
   "source": [
    "example_text='There is cardiomegaly. No evidence of pleural effusion. No evidence of consolidation.'\n",
    "\n",
    "example=tokenize_function(example_text)\n",
    "for item in example.keys():\n",
    "    example[item] = example[item].cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    feature = model(**example)\n",
    "    \n",
    "feature_np = feature.hidden_states[-1][:, :save_seq_len, :].detach().cpu().numpy()\n",
    "print(feature_np.shape)\n",
    "\n",
    "np.save(\"./results/text_embed_example/with_cardiomegaly_v4.npy\", feature_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b58931",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_1_11",
   "language": "python",
   "name": "torch_1_11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
